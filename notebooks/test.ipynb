{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "- Odd one out with numbers of answers\n",
    "- [urgent] Word topic matching is very wrong format -> do numbers make sense here?\n",
    "- There should be free text answers!\n",
    "- [urgent] for gap text, implement free text answers more clearly. sometimes the gap number repeats\n",
    "  - test the free text answer formatting here\n",
    "  - sometimes provides correct answers in the correct order\n",
    "- code the level upgrade in python logic\n",
    "- code the level assessment somehow -> there should be a way to input the language level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'temimbo' from 'c:\\\\Users\\\\franz\\\\OneDrive\\\\Desktop\\\\BA\\\\BA\\\\LanguageTeacher\\\\notebooks\\\\..\\\\temimbo\\\\__init__.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import temimbo\n",
    "\n",
    "import importlib\n",
    "\n",
    "importlib.reload(temimbo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "connector_openai = temimbo.ConnectorOpenAI(\n",
    "    openai_key = os.getenv('OPENAI_KEY')\n",
    ")\n",
    "tg = temimbo.TaskGenerator(connector_llm = connector_openai)\n",
    "evaluator = temimbo.AnswerEvaluator(connector_llm = connector_openai)\n",
    "\n",
    "\n",
    "ui = temimbo.UserInterface()\n",
    "db = temimbo.DatabaseClientLocalFile(connection_string='./database')\n",
    "formater = temimbo.Formater()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = await db.load_profile(id='Franzy')\n",
    "domain = await ui.choose_domain(domain='text')\n",
    "task_type = await ui.choose_task_type(task_type='single_choice')\n",
    "level, training_goals_subset = await tg.incorporate_profile_in_task(profile, domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretend you are a academic english teacher. Generate a task description, and the task according to the format of the examples. No other text or tasks.\n",
      "Generate a single choice with given answer possibilities, only one of the answers is correct. Generate only one task with four answer possibilities. Generate it for the area of text teaching, targeting on Describe delicious things.\n",
      "Adjust the task dificulty to language level B2 (Can understand the main ideas of complex text on both concrete and abstract topics, including technical discussions in his/her field of specialisation. Can interact with a degree of fluency and spontaneity that makes regular interaction with native speakers quite possible without strain for either party. Can produce clear, detailed text on a wide range of subjects and explain a viewpoint on a topical issue giving the advantages and disadvantages of various options).\n",
      "\n",
      "The following are 2 examples of how the task should be generated with output format and style:\n",
      "\n",
      " Select the correct answer:\n",
      "She _____ robbed when she left the chocolate factory.\n",
      "a) were\n",
      "b) did\n",
      "c) was\n",
      "d) forgot\n",
      "\n",
      " Select the correct answer:\n",
      "He is working on his computer with his baby next to _____ \n",
      "a) himself\n",
      "b) his\n",
      "c) herself\n",
      "d) itself\n"
     ]
    }
   ],
   "source": [
    "prompt = await tg.generate_prompt(\n",
    "    level = level,\n",
    "    training_goals_subset = training_goals_subset,\n",
    "    domain = domain,\n",
    "    task_type = task_type,\n",
    ")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select the correct answer:\n",
      "Which word best describes the taste of a perfectly ripe mango?\n",
      "a) Sweet\n",
      "b) Salty\n",
      "c) Bitter\n",
      "d) Sour\n"
     ]
    }
   ],
   "source": [
    "raw_output = await tg.generate_task(prompt)\n",
    "print(raw_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_output_task = await formater.output_task_formatting(raw_output)\n",
    "user_answer = await ui.answer_task(formatted_output_task, answer=\"c\")\n",
    "formated_user_answer = await formater.learner_answer_formatting(user_answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NL_feedback = Good effort! However, the correct answer is 'a) Sweet'. A perfectly ripe mango is known for its sweet taste. Keep practicing vocabulary and understanding the meaning of the question. You'll get it next time! Keep up the good work!\n",
      "correctness = False\n",
      "training_goals = vocabulary_goals=['mango'] grammar_goals=['adjective agreement (ripe)'] text_goals=['understanding of the question']\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "# This is what it will actually looks like\n",
    "NL_feedback, correctness, training_goals = await evaluator.evaluate_learner_answer(\n",
    "    domain = domain,\n",
    "    formatted_output_task = formatted_output_task,\n",
    "    formated_user_answer = formated_user_answer,\n",
    "    task_type = task_type,\n",
    ")\n",
    "print('NL_feedback =', NL_feedback)\n",
    "print('correctness =', correctness)\n",
    "print('training_goals =', training_goals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# While the parsing is not implemented, this function will not work\n",
    "new_profile = await evaluator.update_learner_profile(training_goals,domain, profile, correctness)\n",
    "#print(f'Old profile:\\n{profile}\\n\\nNew profile:\\n{new_profile}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='Franzy' level=Level(vocabulary_level=5.5, grammar_level=7.9, text_level=2.9) training_goals=TrainingGoals(vocabulary_goals=['Cats and puppies', 'mango'], grammar_goals=['adjective agreement (ripe)'], text_goals=['Describe delicious things', 'understanding of the question'])\n"
     ]
    }
   ],
   "source": [
    "print(new_profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This overwrites the original profile\n",
    "# For testing purposes, it's easier to just comment it out\n",
    "await db.save_profile(new_profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "25e6fefa8d138d67568049bc3e2c682d1e448d08136aef81ded8b5c62321466c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
