{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "- Odd one out with numbers of answers\n",
    "- [urgent] Word topic matching is very wrong format -> do numbers make sense here?\n",
    "- There should be free text answers!\n",
    "- [urgent] for gap text, implement free text answers more clearly. sometimes the gap number repeats\n",
    "  - test the free text answer formatting here\n",
    "  - sometimes provides correct answers in the correct order\n",
    "- code the level upgrade in python logic\n",
    "- code the level assessment somehow -> there should be a way to input the language level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'temimbo' from 'c:\\\\Users\\\\franz\\\\OneDrive\\\\Desktop\\\\BA\\\\BA\\\\LanguageTeacher\\\\notebooks\\\\..\\\\temimbo\\\\__init__.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import temimbo\n",
    "\n",
    "import importlib\n",
    "importlib.reload(temimbo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "connector_openai = temimbo.ConnectorOpenAI(\n",
    "    openai_key = os.getenv('OPENAI_KEY')\n",
    ")\n",
    "tg = temimbo.TaskGenerator(connector_llm = connector_openai)\n",
    "evaluator = temimbo.AnswerEvaluator(connector_llm = connector_openai)\n",
    "\n",
    "\n",
    "ui = temimbo.UserInterface()\n",
    "db = temimbo.DatabaseClientLocalFile(connection_string='./database')\n",
    "formater = temimbo.Formater()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = await db.load_profile(id='Franzy')\n",
    "domain = await ui.choose_domain(domain='vocabulary')\n",
    "task_type = await ui.choose_task_type(task_type='multiple_choice')\n",
    "level, training_goals_subset = await tg.incorporate_profile_in_task(profile, domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretend you are a academic english teacher. Generate a task description, and the task according to the format of the examples. No other text or tasks.\n",
      "Generate a multiple choice with given answer possibilities, there can be multiple correct answers. Generate only one task with four answer possibilities. Generate it for the area of grammar teaching, targeting on simple past.\n",
      "Adjust the task dificulty to language level C1 (Can understand a wide range of demanding, longer texts, and recognise implicit meaning. Can express him/herself fluently and spontaneously without much obvious searching for expressions. Can use language flexibly and effectively for social, academic and professional purposes. Can produce clear, well-structured, detailed text on complex subjects, showing controlled use of organisational patterns, connectors and cohesive devices).\n",
      "\n",
      "The following are 2 examples of how the task should be generated with output format and style:\n",
      "\n",
      " Select the correct answers:\n",
      "I am very happy _____ in India. I really miss being there.\n",
      "a) to live\n",
      "b) to have lived\n",
      "c) to be lived\n",
      "d) to have living\n",
      "\n",
      " Select the correct answers:\n",
      "They did not reach an agreement ______ their differences.\n",
      "a) because of\n",
      "b) due to\n",
      "c) even though\n",
      "d) besides\n"
     ]
    }
   ],
   "source": [
    "prompt = await tg.generate_prompt(\n",
    "    level = level,\n",
    "    training_goals_subset = training_goals_subset,\n",
    "    domain = domain,\n",
    "    task_type = task_type,\n",
    ")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identify the correct form of the verb in the simple past tense:\n",
      "\n",
      "John _______ his homework before going to bed.\n",
      "a) finished\n",
      "b) finish\n",
      "c) finishes\n",
      "d) will finish\n"
     ]
    }
   ],
   "source": [
    "raw_output = await tg.generate_task(prompt)\n",
    "print(raw_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_output_task = await formater.output_task_formatting(raw_output)\n",
    "user_answer = await ui.answer_task(formatted_output_task, answer=\"b)\")\n",
    "formated_user_answer = await formater.learner_answer_formatting(user_answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NL_feedback = I'm sorry, but your answer is incorrect. The correct answer is 'a) bend them'. The verb 'like' calls for the base form of the verb 'bend'. So it should be 'I like to bend them'. You should practice more on verb forms and pay attention to the verb patterns. Keep up the good work and try again!\n",
      "correctness = wrong\n",
      "training_goals = No training goals.\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "# This is what it will actually looks like\n",
    "NL_feedback, correctness, training_goals = await evaluator.evaluate_learner_answer(\n",
    "    domain = domain,\n",
    "    formatted_output_task = formatted_output_task,\n",
    "    formated_user_answer = formated_user_answer,\n",
    "    task_type = task_type,\n",
    ")\n",
    "print('NL_feedback =', NL_feedback)\n",
    "print('correctness =', correctness)\n",
    "print('training_goals =', training_goals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# While the parsing is not implemented, this function will not work\n",
    "#new_profile = await evaluator.update_learner_profile(training_goals, profile)\n",
    "#print(f'Old profile:\\n{profile}\\n\\nNew profile:\\n{new_profile}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This overwrites the original profile\n",
    "# For testing purposes, it's easier to just comment it out\n",
    "# await db.save_profile(new_profile)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "25e6fefa8d138d67568049bc3e2c682d1e448d08136aef81ded8b5c62321466c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
